experiment_type: nn
Architecture:
  class: Transformer
  parameters:
    seq_len: 20
    d_model: 128
    n_heads: 16
    num_layers: 4
    est_head_dim: 128
    output_size: 1
    dropout_rate: 0.00307601047978035
    est_head_dropout: 0.15892555589736823
    activation: "relu"
Training:
  seed: 42
  dataset_id: TennesseeEastmanProcess
  dataset_class: SequentialDataset
  batch_size: 256
  num_epochs: 100
  optimizer: Adam
  optimizer_params:
    lr: 0.00025525091258394813
  loss_function: MSELoss