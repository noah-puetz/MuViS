experiment_type: nn
Architecture:
  class: LSTM
  parameters:
    output_size: 1
    hidden_size: 64
    fc_units: 256
    num_layers: 1
    dropout1: 0.12411373569813709
    dropout2: 0.09655091338730282
Training:
  seed: 42
  dataset_id: BeijingPM25Quality
  dataset_class: SequentialDataset
  batch_size: 256
  num_epochs: 100
  optimizer: Adam
  optimizer_params:
    lr: 0.003066453247362052
  loss_function: MSELoss
